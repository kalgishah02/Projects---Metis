{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import Pyro4\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "# NLP tools\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "import gensim\n",
    "from gensim.matutils import Sparse2Corpus, corpus2dense\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from __future__ import print_function, division\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import NMF\n",
    "# Python 2 compatibility\n",
    "from __future__ import print_function\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_train = pd.read_csv(\"/home/kalgi/train.csv\")\n",
    "question1 = questions_train.iloc[:,4]\n",
    "question2 = questions_train['question2']\n",
    "questions_all = pd.concat([question1, question2], axis=0).reset_index()\n",
    "questions = (questions_all['question2'][:100000]).reset_index()\n",
    "question_list = list(questions)\n",
    "result = []\n",
    "for i in question_list:\n",
    "    if str(i) != 'nan':\n",
    "        result.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count Vectorizer & LDA\n",
    "english_stemmer = PorterStemmer()\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "cnt = StemmedCountVectorizer(stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", min_df=200, \n",
    "                      max_df=0.8, ngram_range=(1,3))\n",
    "count_vec = cnt.fit(questions['question2'])\n",
    "counts = count_vec.transform(questions['question2']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt_corpus = Sparse2Corpus(counts)\n",
    "id2word_count = dict((v, k) for k, v in cnt.vocabulary_.items())\n",
    "id2word_count = corpora.Dictionary.from_corpus(cnt_corpus, \n",
    "                                         id2word=id2word_count)\n",
    "lda = models.LdaMulticore(corpus=cnt_corpus, num_topics=12, id2word=id2word_count, passes=50, eval_every=10, workers=8)\n",
    "lda_corpus = lda[cnt_corpus]\n",
    "#topic_probs = list(lda_corpus)\n",
    "#questions['topic_probs'] = pd.Series(topic_probs)\n",
    "#questions['topic_probs'] = questions['topic_probs'].apply(lambda row: sorted(row, key=lambda x: x[1], reverse=True))\n",
    "#questions.to_csv('/dev/qt.csv')\n",
    "lda_docs = [doc for doc in lda_corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.5877509806920713"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = CoherenceModel(model=lda, corpus=cnt_corpus, dictionary=id2word, coherence='u_mass')\n",
    "cm.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.055*\"english\" + 0.045*\"weight\" + 0.041*\"lose\" + 0.041*\"improv\" + 0.038*\"place\" + 0.035*\"comput\" + 0.032*\"scienc\" + 0.030*\"data\" + 0.028*\"song\" + 0.026*\"men\" + 0.025*\"china\" + 0.025*\"idea\" + 0.024*\"visit\" + 0.023*\"women\" + 0.022*\"hair\" + 0.022*\"consid\" + 0.021*\"skill\" + 0.020*\"rid\" + 0.020*\"lose weight\" + 0.019*\"histori\" + 0.019*\"speak\" + 0.018*\"big\" + 0.018*\"citi\" + 0.018*\"plan\" + 0.017*\"option\" + 0.017*\"form\" + 0.016*\"startup\" + 0.015*\"bodi\" + 0.015*\"gain\" + 0.014*\"commun\"'),\n",
       " (1,\n",
       "  '0.108*\"like\" + 0.104*\"make\" + 0.065*\"money\" + 0.043*\"girl\" + 0.039*\"don\" + 0.032*\"onlin\" + 0.031*\"friend\" + 0.031*\"want\" + 0.026*\"peopl\" + 0.026*\"sex\" + 0.023*\"guy\" + 0.023*\"realli\" + 0.021*\"earn\" + 0.020*\"look\" + 0.018*\"know\" + 0.018*\"market\" + 0.017*\"tell\" + 0.016*\"date\" + 0.016*\"make money\" + 0.015*\"exist\" + 0.015*\"mind\" + 0.013*\"control\" + 0.013*\"god\" + 0.013*\"man\" + 0.012*\"talk\" + 0.012*\"file\" + 0.011*\"digit\" + 0.011*\"earn money\" + 0.011*\"money onlin\" + 0.010*\"feel\"'),\n",
       " (2,\n",
       "  '0.078*\"time\" + 0.068*\"life\" + 0.051*\"engin\" + 0.034*\"prepar\" + 0.031*\"studi\" + 0.030*\"student\" + 0.027*\"colleg\" + 0.023*\"exam\" + 0.023*\"come\" + 0.021*\"year\" + 0.020*\"real\" + 0.018*\"travel\" + 0.016*\"appli\" + 0.015*\"class\" + 0.015*\"invest\" + 0.014*\"mechan\" + 0.013*\"manag\" + 0.013*\"build\" + 0.012*\"univers\" + 0.012*\"cours\" + 0.012*\"complet\" + 0.012*\"graduat\" + 0.011*\"salari\" + 0.011*\"requir\" + 0.011*\"stock\" + 0.011*\"futur\" + 0.010*\"mba\" + 0.010*\"cat\" + 0.010*\"worth\" + 0.010*\"want\"'),\n",
       " (3,\n",
       "  '0.100*\"peopl\" + 0.099*\"differ\" + 0.088*\"quora\" + 0.059*\"question\" + 0.049*\"trump\" + 0.037*\"ask\" + 0.036*\"person\" + 0.032*\"answer\" + 0.031*\"donald\" + 0.030*\"donald trump\" + 0.030*\"presid\" + 0.027*\"win\" + 0.025*\"math\" + 0.023*\"clinton\" + 0.022*\"elect\" + 0.021*\"number\" + 0.019*\"hillari\" + 0.018*\"support\" + 0.017*\"hillary clinton\" + 0.014*\"tip\" + 0.014*\"chang\" + 0.011*\"vote\" + 0.011*\"questions quora\" + 0.011*\"need\" + 0.010*\"won\" + 0.010*\"self\" + 0.009*\"mark\" + 0.009*\"improv\" + 0.009*\"googl\" + 0.009*\"easili\"'),\n",
       " (4,\n",
       "  '0.063*\"thing\" + 0.062*\"start\" + 0.054*\"day\" + 0.053*\"know\" + 0.049*\"love\" + 0.030*\"import\" + 0.028*\"read\" + 0.027*\"go\" + 0.026*\"busi\" + 0.026*\"human\" + 0.025*\"school\" + 0.022*\"test\" + 0.022*\"right\" + 0.022*\"write\" + 0.021*\"long\" + 0.019*\"high\" + 0.018*\"relationship\" + 0.017*\"problem\" + 0.016*\"password\" + 0.015*\"email\" + 0.015*\"end\" + 0.015*\"month\" + 0.014*\"new\" + 0.014*\"favorit\" + 0.013*\"current\" + 0.013*\"gmail\" + 0.013*\"book\" + 0.012*\"period\" + 0.012*\"call\" + 0.011*\"employe\"'),\n",
       " (5,\n",
       "  '0.156*\"use\" + 0.045*\"account\" + 0.032*\"websit\" + 0.030*\"facebook\" + 0.028*\"googl\" + 0.027*\"instagram\" + 0.026*\"free\" + 0.026*\"creat\" + 0.024*\"increas\" + 0.024*\"follow\" + 0.023*\"hack\" + 0.021*\"view\" + 0.020*\"video\" + 0.018*\"delet\" + 0.018*\"cost\" + 0.017*\"eat\" + 0.016*\"messag\" + 0.016*\"whatsapp\" + 0.016*\"non\" + 0.016*\"experi\" + 0.015*\"youtub\" + 0.015*\"review\" + 0.015*\"hotel\" + 0.014*\"polic\" + 0.014*\"block\" + 0.013*\"code\" + 0.013*\"dream\" + 0.013*\"kill\" + 0.013*\"height\" + 0.013*\"applic\"'),\n",
       " (6,\n",
       "  '0.286*\"doe\" + 0.082*\"work\" + 0.063*\"mean\" + 0.043*\"feel\" + 0.043*\"happen\" + 0.029*\"compar\" + 0.028*\"effect\" + 0.026*\"univers\" + 0.026*\"major\" + 0.020*\"energi\" + 0.019*\"earth\" + 0.018*\"american\" + 0.018*\"does mean\" + 0.017*\"bad\" + 0.017*\"like\" + 0.014*\"term\" + 0.013*\"does feel\" + 0.013*\"posit\" + 0.013*\"woman\" + 0.013*\"feel lik\" + 0.012*\"light\" + 0.012*\"intern\" + 0.012*\"type\" + 0.012*\"long\" + 0.011*\"speed\" + 0.010*\"space\" + 0.010*\"point\" + 0.010*\"say\" + 0.009*\"hard\" + 0.009*\"recruit\"'),\n",
       " (7,\n",
       "  '0.287*\"best\" + 0.130*\"way\" + 0.087*\"learn\" + 0.063*\"best way\" + 0.049*\"movi\" + 0.047*\"world\" + 0.046*\"book\" + 0.026*\"state\" + 0.025*\"war\" + 0.015*\"unit\" + 0.014*\"best book\" + 0.013*\"remov\" + 0.012*\"law\" + 0.012*\"stay\" + 0.012*\"america\" + 0.011*\"java\" + 0.010*\"valu\" + 0.010*\"institut\" + 0.010*\"united st\" + 0.010*\"onlin\" + 0.010*\"happi\" + 0.009*\"world war\" + 0.009*\"home\" + 0.009*\"machin\" + 0.008*\"open\" + 0.008*\"model\" + 0.008*\"way learn\" + 0.008*\"program\" + 0.007*\"beginn\" + 0.007*\"site\"'),\n",
       " (8,\n",
       "  '0.119*\"did\" + 0.085*\"think\" + 0.048*\"stop\" + 0.036*\"card\" + 0.035*\"possibl\" + 0.032*\"bank\" + 0.032*\"iphon\" + 0.027*\"com\" + 0.026*\"power\" + 0.025*\"gener\" + 0.024*\"play\" + 0.024*\"die\" + 0.022*\"dog\" + 0.022*\"age\" + 0.020*\"cultur\" + 0.020*\"process\" + 0.020*\"music\" + 0.019*\"score\" + 0.019*\"success\" + 0.019*\"chines\" + 0.018*\"kind\" + 0.018*\"offic\" + 0.017*\"actual\" + 0.017*\"rate\" + 0.017*\"main\" + 0.017*\"function\" + 0.015*\"post\" + 0.015*\"relat\" + 0.015*\"safe\" + 0.015*\"got\"'),\n",
       " (9,\n",
       "  '0.074*\"indian\" + 0.069*\"year\" + 0.054*\"note\" + 0.049*\"new\" + 0.046*\"countri\" + 0.042*\"old\" + 0.038*\"help\" + 0.038*\"need\" + 0.032*\"black\" + 0.032*\"word\" + 0.031*\"exampl\" + 0.028*\"rupe\" + 0.026*\"govern\" + 0.026*\"caus\" + 0.024*\"food\" + 0.023*\"rs\" + 0.023*\"india\" + 0.022*\"ban\" + 0.021*\"year old\" + 0.018*\"white\" + 0.017*\"affect\" + 0.015*\"modi\" + 0.015*\"technolog\" + 0.015*\"sentenc\" + 0.015*\"rupee not\" + 0.014*\"economi\" + 0.013*\"nation\" + 0.013*\"usa\" + 0.013*\"black money\" + 0.013*\"visa\"'),\n",
       " (10,\n",
       "  '0.134*\"india\" + 0.069*\"best\" + 0.049*\"better\" + 0.041*\"buy\" + 0.041*\"phone\" + 0.037*\"languag\" + 0.033*\"program\" + 0.031*\"develop\" + 0.029*\"game\" + 0.025*\"app\" + 0.024*\"servic\" + 0.023*\"watch\" + 0.022*\"android\" + 0.022*\"car\" + 0.020*\"mobil\" + 0.018*\"laptop\" + 0.017*\"tv\" + 0.016*\"pakistan\" + 0.015*\"provid\" + 0.015*\"water\" + 0.014*\"window\" + 0.014*\"programming languag\" + 0.013*\"web\" + 0.012*\"sell\" + 0.012*\"seri\" + 0.012*\"reduc\" + 0.011*\"avail\" + 0.011*\"today\" + 0.011*\"instal\" + 0.010*\"price\"'),\n",
       " (11,\n",
       "  '0.166*\"good\" + 0.072*\"job\" + 0.051*\"compani\" + 0.047*\"live\" + 0.029*\"say\" + 0.026*\"product\" + 0.023*\"interest\" + 0.023*\"true\" + 0.022*\"averag\" + 0.021*\"get\" + 0.021*\"run\" + 0.020*\"social\" + 0.019*\"anim\" + 0.019*\"great\" + 0.018*\"pro\" + 0.018*\"parent\" + 0.018*\"delhi\" + 0.017*\"fact\" + 0.016*\"site\" + 0.016*\"chanc\" + 0.016*\"sleep\" + 0.015*\"download\" + 0.015*\"stori\" + 0.014*\"famili\" + 0.014*\"turn\" + 0.014*\"offer\" + 0.014*\"ve\" + 0.013*\"interview\" + 0.013*\"secur\" + 0.012*\"intellig\"')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['lda_vecs'] = lda_docs\n",
    "lda.print_topics(num_words=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6686, 1.0), (12432, 1.0), (19189, 1.0), (22246, 1.0), (29741, 1.0), (30491, 1.0), (30558, 1.0), (31884, 1.0), (32465, 1.0), (37995, 1.0)]\n",
      "Is it safe for a woman to travel alone in Japan?\n",
      "What purpose does the nuclear membrane serve? What are its functions?\n",
      "When and where did the term \"venture capital\" come to being?\n",
      "How do jet engines actually work?\n",
      "I got a package of 3.3 lakh per annum. What is my monthly salary after all the calculations?\n",
      "What's your feeling about the Chinese films?\n",
      "How much power does my 40W lamp consume in 1 hour?\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(questions['lda_vecs'],\n",
    "                                      num_features=300)\n",
    "sorted_sims = sorted(enumerate(index[questions['lda_vecs'][10000]]), key=lambda item: -item[1])\n",
    "print(sorted_sims[0:10])\n",
    "print(questions['question2'][10000])\n",
    "print(questions['question2'][6686])\n",
    "print(questions['question2'][12432])\n",
    "print(questions['question2'][19189])\n",
    "print(questions['question2'][22246])\n",
    "print(questions['question2'][29741])\n",
    "print(questions['question2'][30491])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What keeps childern active and far from phone and video games? 7, 9, 0\n",
    "Where can I host a Java website for free like 000WebHost? 7, 4\n",
    "Has perpetual motion or any free energy generator been achieved? If no, is it even possible to achieve it? If yes, how close are we to achieve it? 2,4,9\n",
    "If you view a video on someone's timeline that you aren't friends with can they see you viewed it? 5,7\n",
    "Friends (TV series): What would have changed if Matt LeBlanc played Chandler Bing? 4,8\n",
    "How do you track down a person if you know their name and the rough area of where they live? 8,7,9\n",
    "What will you do if you regret your choices later and now you can not change it and have to live with it for whole life? 8,7,5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
