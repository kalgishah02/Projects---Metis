{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import Pyro4\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "plt.switch_backend('agg')\n",
    "% matplotlib inline\n",
    "import seaborn as sns\n",
    "# NLP tools\n",
    "import nltk\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "import gensim\n",
    "from gensim.matutils import Sparse2Corpus, corpus2dense\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from __future__ import print_function, division\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import sklearn.metrics.pairwise as smp\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import NMF\n",
    "# Python 2 compatibility\n",
    "from __future__ import print_function\n",
    "# logging for gensim (set to INFO)\n",
    "import logging\n",
    "from nltk.corpus import stopwords\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_train = pd.read_csv(\"/home/kalgi/train.csv\")\n",
    "question1 = questions_train.iloc[:,4]\n",
    "question2 = questions_train['question2']\n",
    "questions_all = pd.concat([question1, question2], axis=0).reset_index()\n",
    "questions = (questions_all['question2'][:100000]).reset_index()\n",
    "questions.dropna()\n",
    "question_list = list(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tfidf & LSA\n",
    "english_stemmer = PorterStemmer()\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([english_stemmer.stem(w) for w in analyzer(doc)])\n",
    "tfidf = StemmedCountVectorizer(stop_words='english', token_pattern=\"\\\\b[a-z][a-z]+\\\\b\", min_df=200, \n",
    "                      max_df=0.8, ngram_range=(1,3))\n",
    "tfidf_vecs = tfidf.fit_transform(questions['question2'])\n",
    "tfidf_corpus = Sparse2Corpus(tfidf_vecs.transpose())\n",
    "id2word = dict((v, k) for k, v in tfidf.vocabulary_.items())\n",
    "id2word = corpora.Dictionary.from_corpus(tfidf_corpus, \n",
    "                                         id2word=id2word)\n",
    "lsi = models.LsiModel(tfidf_corpus, id2word=id2word, num_topics=200)\n",
    "lsi_corpus = lsi[tfidf_corpus]\n",
    "doc_vecs = [doc for doc in lsi_corpus]\n",
    "questions['LSI_vecs'] = doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-d51349de0d1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's take a look at how we did\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msim_doc_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim_score\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Document: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msim_doc_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float32' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Let's take a look at how we did\n",
    "for sim_doc_id, sim_score in sims[0:3]: \n",
    "    print(\"Score: \" + str(sim_score))\n",
    "    print(\"Document: \" + questions['question2'][sim_doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5371, 1.0), (9690, 1.0), (10506, 1.0), (11116, 1.0), (13478, 1.0), (13597, 1.0)]\n",
      "How do I avoid sleep so much?\n",
      "How do I avoid sleep so much?\n",
      "How should I avoid sleeping during lectures?\n",
      "How would you overcome the fear of sleeping alone?\n",
      "How do you treat sleep apnea without CPAP?\n",
      "Do I have brain damage from sleep deprivation?\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(questions['LSI_vecs'],\n",
    "                                      num_features=300)\n",
    "sorted_sims = sorted(enumerate(index[questions['LSI_vecs'][95000]]), key=lambda item: -item[1])\n",
    "print(sorted_sims[0:6])\n",
    "print(questions['question2'][95000])\n",
    "print(questions['question2'][5371])\n",
    "print(questions['question2'][9690])\n",
    "print(questions['question2'][10506])\n",
    "print(questions['question2'][11116])\n",
    "print(questions['question2'][13478])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-d33d68533426>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0msims_with_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0msorted_sims_with_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msims_with_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0msims_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_sims_with_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0msims_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "#similarities for tfidf-lsa\n",
    "index = similarities.MatrixSimilarity(doc_vecs, \n",
    "                                      num_features=len(id2word))\n",
    "with open('/dev/sims','w') as sims_output:\n",
    "    for i, sims in enumerate(index):\n",
    "        sims_with_labels = [(score, questions['question2'][j]) for j, score in enumerate(sims)]\n",
    "        sorted_sims_with_labels = sorted(sims_with_labels, reverse=True)\n",
    "        sims_output.write(str(sorted_sims_with_labels))\n",
    "        sims_output.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ng_lsi = corpus2dense(lsi_corpus, num_terms=100).transpose()\n",
    "km = KMeans(n_clusters=10, random_state=1, n_jobs= 8)\n",
    "km.fit_predict(ng_lsi)\n",
    "questions['labels'] = km.labels_\n",
    "Sil_coefs.append(metrics.silhouette_score(ng_lsi, labels, metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(3,10)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierarchial = AgglomerativeClustering(n_clusters=10,\n",
    "                                    linkage=\"average\", affinity='cosine')\n",
    "hierarchial.fit(ng_lsi)\n",
    "questions['labels_hierarchial'] = hierarchial.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
